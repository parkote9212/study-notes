---
tags:
  - study
  - spring
  - advanced
  - batch
  - spring-batch
created: 2025-02-08
---

# 배치처리 기초

## 한 줄 요약
> Spring Batch는 대용량 데이터를 효율적으로 처리하기 위한 프레임워크로, 읽기-처리-쓰기 단계를 청크 단위로 나누어 안정적이고 재시작 가능한 배치 작업을 구현한다.

## 상세 설명

### 배치 처리란?
- **대량의 데이터**를 **일괄 처리**
- **사용자 개입 없이** 자동 실행
- **정해진 시간**에 실행 (보통 야간)

### 왜 배치 처리가 필요한가?
```java
// ❌ 실시간 처리: 100만 건 처리 시 시스템 부하
@PostMapping("/process-all")
public void processAllOrders() {
    List<Order> orders = orderRepository.findAll();  // 100만 건
    
    for (Order order : orders) {
        processOrder(order);  // 시스템 과부하!
    }
}

// ✅ 배치 처리: 야간에 청크 단위로 처리
@Scheduled(cron = "0 0 2 * * *")  // 새벽 2시
public void batchProcessOrders() {
    // 1000건씩 나누어 처리
    // 중간에 실패해도 재시작 가능
}
```

### 배치 처리 특징
- **대용량**: 수백만 건 이상
- **자동화**: 사람 개입 없음
- **견고성**: 실패 시 재시작, 트랜잭션 관리
- **성능**: 청크 단위 처리, 병렬 처리

### Spring Batch 핵심 개념

```
Job (작업 전체)
  ↓
Step (단계)
  ↓
Chunk (청크 단위 처리)
  ↓
Read → Process → Write
```

### Spring Batch 구성 요소

| 구성 요소 | 설명 | 예시 |
|---------|------|------|
| **Job** | 배치 작업 전체 | 일일 정산 Job |
| **Step** | Job 내부의 독립 단계 | 데이터 읽기 → 변환 → 저장 |
| **ItemReader** | 데이터 읽기 | DB, 파일, API |
| **ItemProcessor** | 데이터 처리/변환 | 검증, 변환, 필터링 |
| **ItemWriter** | 데이터 쓰기 | DB, 파일 저장 |
| **Chunk** | 처리 단위 | 1000건씩 |

## 코드 예시

```java
// 1. Spring Batch 의존성
// build.gradle
// implementation 'org.springframework.boot:spring-boot-starter-batch'

// 2. @EnableBatchProcessing 활성화
@EnableBatchProcessing
@Configuration
public class BatchConfig {
}

// 3. 간단한 Job 생성
@Configuration
@RequiredArgsConstructor
public class SimpleJobConfig {
    
    private final JobRepository jobRepository;
    private final PlatformTransactionManager transactionManager;
    
    @Bean
    public Job simpleJob() {
        return new JobBuilder("simpleJob", jobRepository)
                .start(simpleStep())
                .build();
    }
    
    @Bean
    public Step simpleStep() {
        return new StepBuilder("simpleStep", jobRepository)
                .tasklet((contribution, chunkContext) -> {
                    System.out.println("Hello, Spring Batch!");
                    return RepeatStatus.FINISHED;
                }, transactionManager)
                .build();
    }
}

// 4. Chunk 기반 Step (가장 많이 사용)
@Configuration
@RequiredArgsConstructor
public class ChunkJobConfig {
    
    private final JobRepository jobRepository;
    private final PlatformTransactionManager transactionManager;
    private final EntityManagerFactory entityManagerFactory;
    
    @Bean
    public Job chunkJob() {
        return new JobBuilder("chunkJob", jobRepository)
                .start(chunkStep())
                .build();
    }
    
    @Bean
    public Step chunkStep() {
        return new StepBuilder("chunkStep", jobRepository)
                .<Order, OrderDto>chunk(1000, transactionManager)  // 1000건씩 처리
                .reader(orderReader())
                .processor(orderProcessor())
                .writer(orderWriter())
                .build();
    }
    
    @Bean
    public JpaPagingItemReader<Order> orderReader() {
        return new JpaPagingItemReaderBuilder<Order>()
                .name("orderReader")
                .entityManagerFactory(entityManagerFactory)
                .queryString("SELECT o FROM Order o WHERE o.status = 'PENDING'")
                .pageSize(1000)
                .build();
    }
    
    @Bean
    public ItemProcessor<Order, OrderDto> orderProcessor() {
        return order -> {
            // 데이터 변환
            return OrderDto.builder()
                    .orderId(order.getId())
                    .totalAmount(order.getTotalAmount())
                    .build();
        };
    }
    
    @Bean
    public JpaItemWriter<OrderDto> orderWriter() {
        JpaItemWriter<OrderDto> writer = new JpaItemWriter<>();
        writer.setEntityManagerFactory(entityManagerFactory);
        return writer;
    }
}

// 5. CSV 파일 읽기
@Configuration
@RequiredArgsConstructor
public class CsvJobConfig {
    
    @Bean
    public FlatFileItemReader<Product> csvReader() {
        return new FlatFileItemReaderBuilder<Product>()
                .name("csvReader")
                .resource(new ClassPathResource("products.csv"))
                .delimited()
                .names("id", "name", "price")
                .targetType(Product.class)
                .build();
    }
}

// 6. 조건부 Step 실행
@Configuration
@RequiredArgsConstructor
public class ConditionalJobConfig {
    
    @Bean
    public Job conditionalJob() {
        return new JobBuilder("conditionalJob", jobRepository)
                .start(step1())
                .on("COMPLETED").to(step2())  // step1 성공 시 step2 실행
                .from(step1())
                .on("FAILED").to(step3())     // step1 실패 시 step3 실행
                .end()
                .build();
    }
}

// 7. JobParameter (실행 파라미터)
@Configuration
@RequiredArgsConstructor
public class ParameterJobConfig {
    
    @Bean
    @JobScope
    public Step parameterStep(
            @Value("#{jobParameters['date']}") String date) {
        
        return new StepBuilder("parameterStep", jobRepository)
                .tasklet((contribution, chunkContext) -> {
                    System.out.println("처리 날짜: " + date);
                    return RepeatStatus.FINISHED;
                }, transactionManager)
                .build();
    }
}

// Job 실행 (CommandLineRunner 또는 Controller)
@Component
@RequiredArgsConstructor
public class BatchRunner implements CommandLineRunner {
    
    private final JobLauncher jobLauncher;
    private final Job parameterJob;
    
    @Override
    public void run(String... args) throws Exception {
        JobParameters jobParameters = new JobParametersBuilder()
                .addString("date", "2025-02-08")
                .addLong("time", System.currentTimeMillis())  // 중복 실행 방지
                .toJobParameters();
        
        jobLauncher.run(parameterJob, jobParameters);
    }
}

// 8. ItemProcessor에서 필터링
@Bean
public ItemProcessor<Order, Order> filterProcessor() {
    return order -> {
        // null 반환 시 해당 항목 건너뜀
        if (order.getAmount() < 1000) {
            return null;  // 1000원 미만 주문 제외
        }
        return order;
    };
}

// 9. CompositeItemProcessor (여러 Processor 체이닝)
@Bean
public CompositeItemProcessor<Order, OrderDto> compositeProcessor() {
    CompositeItemProcessor<Order, OrderDto> processor = 
        new CompositeItemProcessor<>();
    
    processor.setDelegates(Arrays.asList(
        validationProcessor(),
        transformProcessor()
    ));
    
    return processor;
}

// 10. Skip 예외 처리
@Bean
public Step skipStep() {
    return new StepBuilder("skipStep", jobRepository)
            .<Order, OrderDto>chunk(1000, transactionManager)
            .reader(orderReader())
            .processor(orderProcessor())
            .writer(orderWriter())
            .faultTolerant()  // 예외 허용
            .skip(ValidationException.class)  // 이 예외는 건너뜀
            .skipLimit(10)  // 최대 10건까지 건너뛰기
            .build();
}

// 11. Retry 재시도
@Bean
public Step retryStep() {
    return new StepBuilder("retryStep", jobRepository)
            .<Order, OrderDto>chunk(1000, transactionManager)
            .reader(orderReader())
            .processor(orderProcessor())
            .writer(orderWriter())
            .faultTolerant()
            .retry(NetworkException.class)  // 이 예외는 재시도
            .retryLimit(3)  // 최대 3번 재시도
            .build();
}

// 12. StepExecutionListener (Step 전후 처리)
public class CustomStepListener implements StepExecutionListener {
    
    @Override
    public void beforeStep(StepExecution stepExecution) {
        System.out.println("Step 시작");
    }
    
    @Override
    public ExitStatus afterStep(StepExecution stepExecution) {
        System.out.println("Step 종료");
        System.out.println("Read Count: " + stepExecution.getReadCount());
        System.out.println("Write Count: " + stepExecution.getWriteCount());
        return stepExecution.getExitStatus();
    }
}

@Bean
public Step listenerStep() {
    return new StepBuilder("listenerStep", jobRepository)
            .<Order, OrderDto>chunk(1000, transactionManager)
            .reader(orderReader())
            .processor(orderProcessor())
            .writer(orderWriter())
            .listener(new CustomStepListener())
            .build();
}

// 13. 병렬 처리 (Multi-threaded Step)
@Bean
public Step parallelStep() {
    return new StepBuilder("parallelStep", jobRepository)
            .<Order, OrderDto>chunk(1000, transactionManager)
            .reader(orderReader())
            .processor(orderProcessor())
            .writer(orderWriter())
            .taskExecutor(taskExecutor())  // 멀티 스레드
            .build();
}

@Bean
public TaskExecutor taskExecutor() {
    ThreadPoolTaskExecutor executor = new ThreadPoolTaskExecutor();
    executor.setCorePoolSize(4);
    executor.setMaxPoolSize(8);
    executor.setThreadNamePrefix("batch-");
    executor.initialize();
    return executor;
}

// 14. Partitioning (데이터 분할 처리)
@Bean
public Step partitionStep() {
    return new StepBuilder("partitionStep", jobRepository)
            .partitioner("workerStep", partitioner())
            .step(workerStep())
            .gridSize(4)  // 4개로 분할
            .taskExecutor(taskExecutor())
            .build();
}

@Bean
public Partitioner partitioner() {
    return gridSize -> {
        Map<String, ExecutionContext> map = new HashMap<>();
        
        // 데이터를 4개로 분할
        for (int i = 0; i < gridSize; i++) {
            ExecutionContext context = new ExecutionContext();
            context.putInt("minId", i * 1000);
            context.putInt("maxId", (i + 1) * 1000);
            map.put("partition" + i, context);
        }
        
        return map;
    };
}

// 15. Job 재시작 (실패한 Job 재실행)
@Bean
public Job restartableJob() {
    return new JobBuilder("restartableJob", jobRepository)
            .start(restartableStep())
            .build();
}

@Bean
public Step restartableStep() {
    return new StepBuilder("restartableStep", jobRepository)
            .<Order, OrderDto>chunk(1000, transactionManager)
            .reader(orderReader())
            .processor(orderProcessor())
            .writer(orderWriter())
            .build();
}

// Job 재시작
JobExecution execution = jobLauncher.run(
    restartableJob,
    jobParameters
);

if (execution.getStatus() == BatchStatus.FAILED) {
    // 실패한 Job 재시작
    jobLauncher.run(
        restartableJob,
        jobParameters  // 같은 파라미터로 재시작
    );
}

// 16. 커스텀 ItemWriter
public class CustomItemWriter implements ItemWriter<OrderDto> {
    
    @Override
    public void write(Chunk<? extends OrderDto> items) throws Exception {
        for (OrderDto item : items) {
            // 커스텀 쓰기 로직
            System.out.println("Writing: " + item);
        }
    }
}

// 17. ExecutionContext (Step 간 데이터 공유)
@Bean
public Step step1() {
    return new StepBuilder("step1", jobRepository)
            .tasklet((contribution, chunkContext) -> {
                // ExecutionContext에 데이터 저장
                ExecutionContext jobContext = chunkContext
                        .getStepContext()
                        .getStepExecution()
                        .getJobExecution()
                        .getExecutionContext();
                
                jobContext.put("totalAmount", 10000);
                
                return RepeatStatus.FINISHED;
            }, transactionManager)
            .build();
}

@Bean
public Step step2() {
    return new StepBuilder("step2", jobRepository)
            .tasklet((contribution, chunkContext) -> {
                // ExecutionContext에서 데이터 읽기
                ExecutionContext jobContext = chunkContext
                        .getStepContext()
                        .getStepExecution()
                        .getJobExecution()
                        .getExecutionContext();
                
                int totalAmount = jobContext.getInt("totalAmount");
                System.out.println("Total: " + totalAmount);
                
                return RepeatStatus.FINISHED;
            }, transactionManager)
            .build();
}
```

## 주의사항 / 함정

### 1. Reader의 Thread-safety
```java
// ❌ JpaItemReader는 thread-safe 하지 않음
@Bean
public Step parallelStep() {
    return stepBuilder
            .chunk(1000)
            .reader(jpaItemReader())  // 멀티 스레드에서 문제!
            .taskExecutor(taskExecutor())
            .build();
}

// ✅ JpaPagingItemReader 사용
@Bean
public JpaPagingItemReader<Order> jpaPagingItemReader() {
    // Paging 방식은 thread-safe
}
```

### 2. Chunk 크기 설정
```java
// ❌ Chunk 너무 작음 → 커밋 빈번 (느림)
.chunk(10)

// ❌ Chunk 너무 큼 → 메모리 부족
.chunk(100000)

// ✅ 적절한 크기 (1000~5000)
.chunk(1000)
```

### 3. JobParameter 중복 실행
```java
// ❌ 같은 파라미터로는 중복 실행 안 됨
JobParameters params = new JobParametersBuilder()
        .addString("date", "2025-02-08")
        .toJobParameters();

jobLauncher.run(job, params);  // 성공
jobLauncher.run(job, params);  // ❌ 실패!

// ✅ 매번 다른 파라미터 추가
JobParameters params = new JobParametersBuilder()
        .addString("date", "2025-02-08")
        .addLong("time", System.currentTimeMillis())  // 유니크
        .toJobParameters();
```

### 4. Skip vs Retry
```java
// Skip: 예외 발생 항목 건너뛰기 (데이터 손실)
.skip(ValidationException.class)
.skipLimit(10)

// Retry: 예외 발생 시 재시도 (데이터 보존)
.retry(NetworkException.class)
.retryLimit(3)

// 적절히 조합
.skip(ValidationException.class)  // 검증 실패는 건너뛰기
.retry(NetworkException.class)    // 네트워크 오류는 재시도
```

### 5. @JobScope, @StepScope 사용
```java
// ❌ JobParameter 주입 안 됨
@Bean
public Step step(@Value("#{jobParameters['date']}") String date) {
    // date == null!
}

// ✅ @StepScope 필수
@Bean
@StepScope
public Step step(@Value("#{jobParameters['date']}") String date) {
    // date 주입됨
}
```

### 6. 트랜잭션 크기
```java
// ❌ Chunk 크기 != 트랜잭션 크기
.chunk(1000)  // 1000건씩 읽음
// 하지만 트랜잭션은 chunk 단위 (1000건 커밋)
// 중간에 실패하면 1000건 모두 롤백!

// ✅ 적절한 chunk 크기로 트랜잭션 최소화
.chunk(100)  // 100건씩 커밋
```

### 7. 메타 데이터 테이블
```sql
-- Spring Batch는 메타 데이터 테이블 필요
BATCH_JOB_INSTANCE
BATCH_JOB_EXECUTION
BATCH_STEP_EXECUTION
-- 없으면 에러 발생!
```

## 관련 개념
- [[스케줄링]]
- [[트랜잭션-관리]]
- [[비동기처리-Async]]

## 면접 질문

1. **Spring Batch의 핵심 구성 요소는?**
   - Job, Step, ItemReader, ItemProcessor, ItemWriter

2. **Chunk 지향 처리란?**
   - 데이터를 N건씩 나누어 읽기-처리-쓰기
   - 트랜잭션 단위 설정 가능

3. **Skip과 Retry의 차이는?**
   - Skip: 예외 발생 항목 건너뛰기 (데이터 손실)
   - Retry: 예외 발생 시 재시도 (데이터 보존)

4. **JobParameter의 역할은?**
   - Job 실행 시 파라미터 전달
   - 같은 파라미터로 중복 실행 방지
   - Job 식별자 역할

5. **배치 처리를 사용하는 시나리오는?**
   - 대량 데이터 처리
   - 야간 배치 (정산, 통계)
   - ETL 작업

6. **Step 병렬 처리 방법은?**
   - Multi-threaded Step (taskExecutor)
   - Partitioning (데이터 분할)
   - Parallel Steps (여러 Step 동시 실행)

7. **ItemReader가 thread-safe 해야 하는 이유는?**
   - 병렬 처리 시 데이터 중복/누락 방지
   - JpaPagingItemReader 사용 권장

## 참고 자료
- Spring Batch Reference Documentation
- 김영한의 Spring Batch
- https://docs.spring.io/spring-batch/reference/
